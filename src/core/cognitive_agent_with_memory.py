# filepath: c:\dev\human_ai_local\src\core\cognitive_agent.py
"""
Core Cognitive Agent - Central orchestrator for the cognitive architecture
"""
from typing import Dict, List, Optional, Any
from datetime import datetime
import asyncio

from .config import CognitiveConfig
from ..memory.memory_system import MemorySystem

class CognitiveAgent:
    """
    Central cognitive agent that orchestrates all cognitive processes
    
    This class implements the main cognitive loop:
    1. Input processing through sensory buffer
    2. Memory retrieval and context building
    3. Attention allocation and focus management
    4. Response generation and memory consolidation
    """
    
    def __init__(self, config: Optional[CognitiveConfig] = None):
        """
        Initialize the cognitive agent
        
        Args:
            config: Configuration object (uses default if None)
        """
        self.config = config or CognitiveConfig.from_env()
        # Temporary simple session ID
        self.session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # Initialize cognitive components
        self._initialize_components()
        
        # Cognitive state
        self.current_fatigue = 0.0
        self.attention_focus = []
        self.active_goals = []
        self.conversation_context = []
        
        print(f"Cognitive agent initialized with session ID: {self.session_id}")
    
    def _initialize_components(self):
        """Initialize all cognitive architecture components"""
        # Memory systems
        self.memory = MemorySystem(
            stm_capacity=self.config.memory.stm_capacity,
            stm_decay_threshold=self.config.memory.stm_decay_threshold,
            ltm_storage_path=self.config.memory.ltm_storage_path
        )
        
        # Attention mechanism (will be implemented)
        # self.attention = AttentionMechanism(self.config.attention)
        
        # Sensory processing (will be implemented)
        # self.sensory_buffer = SensoryBuffer(self.config.processing)
        
        print("Cognitive components initialized")
    
    async def process_input(
        self,
        input_data: str,
        input_type: str = "text",
        context: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        Main cognitive processing loop
        
        Args:
            input_data: Raw input data (text, audio, etc.)
            input_type: Type of input ("text", "audio", "image")
            context: Additional context information
        
        Returns:
            Generated response
        """
        try:
            print(f"Processing {input_type} input: {input_data[:100]}...")
            
            # Step 1: Sensory processing and filtering
            processed_input = await self._process_sensory_input(input_data, input_type)
            
            # Step 2: Memory retrieval and context building
            memory_context = await self._retrieve_memory_context(processed_input)
            
            # Step 3: Attention allocation
            attention_scores = self._calculate_attention_allocation(processed_input, memory_context)
            
            # Step 4: Response generation (placeholder for LLM integration)
            response = await self._generate_response(processed_input, memory_context, attention_scores)
            
            # Step 5: Memory consolidation
            await self._consolidate_memory(input_data, response, attention_scores)
            
            # Step 6: Update cognitive state
            self._update_cognitive_state(attention_scores)
            
            return response
            
        except Exception as e:
            print(f"Error in cognitive processing: {e}")
            return "I encountered an error while processing your request. Please try again."
    
    async def _process_sensory_input(self, input_data: str, input_type: str) -> Dict[str, Any]:
        """Process raw input through sensory buffer"""
        # Placeholder for sensory processing
        return {
            "raw_input": input_data,
            "type": input_type,
            "processed_at": datetime.now(),
            "entropy_score": 0.7,  # Placeholder
            "embedding": None  # Will be generated by processing module
        }
    
    async def _retrieve_memory_context(self, processed_input: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Retrieve relevant memories for context building"""
        try:
            # Use memory system to search for relevant context
            memories = self.memory.search_memories(
                query=processed_input["raw_input"],
                max_results=5
            )
            
            # Convert to expected format
            context_memories = []
            for memory_obj, relevance, source in memories:
                if source == "stm":
                    context_memories.append({
                        "id": memory_obj.id,
                        "content": memory_obj.content,
                        "source": "STM",
                        "relevance": relevance,
                        "timestamp": memory_obj.encoding_time
                    })
                elif source == "ltm":
                    context_memories.append({
                        "id": memory_obj.id,
                        "content": memory_obj.content,
                        "source": "LTM",
                        "relevance": relevance,
                        "timestamp": memory_obj.encoding_time
                    })
            
            return context_memories
        except Exception as e:
            print(f"Error retrieving memory context: {e}")
            return []
    
    def _calculate_attention_allocation(
        self, 
        processed_input: Dict[str, Any], 
        memory_context: List[Dict[str, Any]]
    ) -> Dict[str, float]:
        """Calculate attention scores for different aspects of the input"""
        
        # Placeholder attention calculation
        relevance = 0.8  # How relevant to current conversation
        novelty = 0.6    # How new/unexpected this input is
        emotional_salience = 0.0  # Emotional weight
        
        # Boost relevance if we found related memories
        if memory_context:
            avg_memory_relevance = sum(mem["relevance"] for mem in memory_context) / len(memory_context)
            relevance = min(1.0, relevance + (avg_memory_relevance * 0.2))
        
        # Simple attention score calculation (temporary)
        attention_score = (relevance * 0.7) + (novelty * 0.3) - (self.current_fatigue * 0.2)
        attention_score = max(0.0, min(1.0, attention_score))
        
        return {
            "overall_attention": attention_score,
            "relevance": relevance,
            "novelty": novelty,
            "emotional_salience": emotional_salience
        }
    
    async def _generate_response(
        self,
        processed_input: Dict[str, Any],
        memory_context: List[Dict[str, Any]],
        attention_scores: Dict[str, float]
    ) -> str:
        """Generate response using LLM with cognitive context"""
        # Enhanced placeholder that includes memory context
        context_info = ""
        if memory_context:
            context_info = f" (I found {len(memory_context)} related memories)"
        
        return f"I understand you said: '{processed_input['raw_input']}'. This is a placeholder response{context_info}."
    
    async def _consolidate_memory(
        self,
        input_data: str,
        response: str,
        attention_scores: Dict[str, float]
    ):
        """Consolidate the interaction into memory"""
        # Create memory ID
        memory_id = f"mem_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
        
        # Store conversation in memory system
        conversation_memory = {
            "interaction": {
                "input": input_data,
                "response": response,
                "timestamp": datetime.now()
            },
            "cognitive_state": {
                "attention_score": attention_scores["overall_attention"],
                "fatigue_level": self.current_fatigue,
                "relevance": attention_scores["relevance"]
            }
        }
        
        # Store in memory system with appropriate importance
        self.memory.store_memory(
            memory_id=memory_id,
            content=conversation_memory,
            importance=attention_scores["relevance"],
            attention_score=attention_scores["overall_attention"],
            emotional_valence=attention_scores["emotional_salience"],
            memory_type="episodic",
            tags=["conversation", "interaction"]
        )
        
        # Also keep in temporary conversation context for immediate access
        memory_entry = {
            "id": memory_id,
            "input": input_data,
            "response": response,
            "timestamp": datetime.now(),
            "attention_score": attention_scores["overall_attention"],
            "importance": attention_scores["relevance"]
        }
        
        self.conversation_context.append(memory_entry)
        
        # Keep only recent context (temporary until proper memory system)
        if len(self.conversation_context) > 10:
            self.conversation_context = self.conversation_context[-10:]
    
    def _update_cognitive_state(self, attention_scores: Dict[str, float]):
        """Update cognitive state based on processing"""
        # Update fatigue (increases with high attention usage)
        attention_cost = attention_scores["overall_attention"] * 0.1
        self.current_fatigue = min(1.0, self.current_fatigue + attention_cost)
        
        # Fatigue recovery (gradual)
        recovery_rate = self.config.attention.attention_recovery_rate
        self.current_fatigue = max(0.0, self.current_fatigue - recovery_rate)
        
        print(f"DEBUG: Updated cognitive state - Fatigue: {self.current_fatigue:.3f}")
    
    def get_cognitive_status(self) -> Dict[str, Any]:
        """Get current cognitive state information"""
        # Get memory system status
        memory_status = self.memory.get_memory_status()
        
        return {
            "session_id": self.session_id,
            "fatigue_level": self.current_fatigue,
            "attention_focus": self.attention_focus,
            "active_goals": self.active_goals,
            "conversation_length": len(self.conversation_context),
            "last_interaction": self.conversation_context[-1]["timestamp"] if self.conversation_context else None,
            "memory_status": memory_status
        }
    
    async def enter_dream_state(self):
        """Enter dream-state processing for memory consolidation"""
        print("Entering dream state for memory consolidation...")
        
        # Use memory system's dream state processing
        dream_results = self.memory.enter_dream_state(duration_minutes=5)
        
        print(f"Dream state results: {dream_results}")
        
        # Reset fatigue after dream processing
        self.current_fatigue = 0.0
        
        print("Dream state processing completed")
    
    async def shutdown(self):
        """Gracefully shutdown the cognitive agent"""
        print("Shutting down cognitive agent...")
        
        # Save any pending memories
        # Close connections
        # Clean up resources
        
        print("Cognitive agent shutdown complete")
